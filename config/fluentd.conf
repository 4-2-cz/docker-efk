<source>
  @type forward
  port  24224
	bind 0.0.0.0
</source>

<filter docker.**>
  @type parser
  format json # apache2, nginx, etc...
  key_name log
  reserve_data true
</filter>

# <filter docker.**>
#   @type concat
#   key log
#   stream_identity_key container_id
#   multiline_start_regexp /^-e:2:in `\/'/
#   multiline_end_regexp /^-e:4:in/
# </filter>

# Store data in Elasticsearch and S3
<match *.**>
  @type copy
  <store>
    @type elasticsearch
    host docker.for.mac.localhost
    port 9200
		index_name fluentd
  	type_name fluentd
    logstash_format true
    logstash_prefix fluentd
    # logstash_dateformat %Y%m%d
    # include_tag_key true
    # type_name access_log
    # tag_key @log_name
    # flush_interval 1s
  </store>
  <store>
    @type stdout
  </store>
  # <store>
  #   type s3
  #   aws_key_id AWS_KEY
  #   aws_sec_key AWS_SECRET
  #   s3_bucket S3_BUCKET
  #   s3_endpoint s3-ap-northeast-1.amazonaws.com
  #   path logs/
  #   buffer_path /var/log/td-agent/buffer/s3
  #   time_slice_format %Y-%m-%d/%H
  #   time_slice_wait 10m
  # </store>
</match>
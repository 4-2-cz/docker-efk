# [SERVICE]
# 	Flush     5
# 	Daemon    Off
# 	Log_Level Debug

# [Input]
# 	Name   forward
# 	Listen 127.0.0.1
# 	PORT   24224

# [Output]
# 	Name  es
# 	Match *
# 	Host  elasticsearch
# 	PORT  9200
# 	Index fluentbit
# 	Type  docker

<source>
  @type forward
  port  24224
	bind 127.0.0.1
</source>

<filter **>
  @type stdout
</filter>

# <match docker.**>
#   @type elasticsearch
#   logstash_format true
#   host 127.0.0.1
#   port 9200
#   flush_interval 5s
# </match>

# Store data in Elasticsearch and S3
<match *.**>
  type copy
  <store>
    type elasticsearch
    host elasticsearch
    port 9200
    include_tag_key true
    tag_key @log_name
    logstash_format true
    flush_interval 10s
    index_name fluentd
    type_name fluentd
  </store>
  # <store>
  #   type s3
  #   aws_key_id AWS_KEY
  #   aws_sec_key AWS_SECRET
  #   s3_bucket S3_BUCKET
  #   s3_endpoint s3-ap-northeast-1.amazonaws.com
  #   path logs/
  #   buffer_path /var/log/td-agent/buffer/s3
  #   time_slice_format %Y-%m-%d/%H
  #   time_slice_wait 10m
  # </store>
</match>

# <label @mainstream>
#   <match **>
#     @type copy
#     <store>
#       @type file
#       @id output_docker1
#       path /fluentd/log/docker.*.log
#       symlink_path /fluentd/log/docker.log
#       append true
#       time_slice_format %Y%m%d
#       time_slice_wait 1m
#       time_format %Y%m%dT%H%M%S%z
#       buffer_path /fluentd/log/docker.*.log
#     </store>
#     <store>
#       @type elasticsearch
#       logstash_format true
#       flush_interval 5s
#       host elasticsearch
#       port 9200
#       index_name fluentd
#       type_name fluentd
#     </store>
#   </match>
# </label>